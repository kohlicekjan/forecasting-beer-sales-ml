{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting beer sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'off-trade_cz' # all_cz, off-trade_cz, on-trade_cz\n",
    "\n",
    "DATA_PATH = f'./data/{DATASET_NAME}_data.csv'\n",
    "\n",
    "MODEL_PATH = f'./models/{DATASET_NAME}_model.joblib'\n",
    "\n",
    "RESULT_CSV_PATH = f'./results/{DATASET_NAME}_result.csv'\n",
    "RESULT_EXCEL_PATH = f'./results/{DATASET_NAME}_result.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH, header=0, decimal=\",\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['SkuShort', 'ProductGroup', 'PrimaryPack', 'Country', 'Year', 'SalesHl', 'OldPredSalesHl'] #'SkuShort', 'ProductGroup', 'PrimaryPack',\n",
    "\n",
    "y = pd.DataFrame(data.SalesHl).round(0).astype(int)\n",
    "X = data.drop(cols_drop, axis=1).fillna(0)\n",
    "\n",
    "X.IsLockdown = X.IsLockdown.astype('bool')\n",
    "# X.SkuShort = X.SkuShort.astype('category')\n",
    "# X.ProductGroup = X.SkuShort.astype('category')\n",
    "# X.PrimaryPack = X.SkuShort.astype('category')\n",
    "# X.Country = X.Country.astype('category')\n",
    "\n",
    "# X.PrevWeekSalesHl1 = X.PrevWeekSalesHl1.round(0).astype(int)\n",
    "# X.PrevWeekSalesHl2 = X.PrevWeekSalesHl2.round(0).astype(int)\n",
    "# X.BgtHl = X.BgtHl.round(0).astype(int)\n",
    "# X.PdtHl = X.PdtHl.round(0).astype(int)\n",
    "\n",
    "\n",
    "y_oldPred = pd.DataFrame(data.OldPredSalesHl).fillna(0).round(0).astype(int)\n",
    "\n",
    "#y.head()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, max_error, mean_absolute_percentage_error\n",
    "\n",
    "from sklearn import ensemble, gaussian_process, isotonic, kernel_ridge, linear_model, neighbors, neural_network, svm, tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Create linear regression object\n",
    "\n",
    "# model = ensemble.AdaBoostRegressor\n",
    "# model = ensemble.BaggingRegressor\n",
    "# model = ensemble.ExtraTreesRegressor\n",
    "# model = ensemble.GradientBoostingRegressor\n",
    "# model = ensemble.RandomForestRegressor\n",
    "# model = ensemble.StackingRegressor\n",
    "# model = ensemble.VotingRegressor\n",
    "# model = ensemble.HistGradientBoostingRegressor\n",
    "\n",
    "#NOT model = gaussian_process.GaussianProcessRegressor\n",
    "# model = isotonic.IsotonicRegression\n",
    "\n",
    "#NOT model = kernel_ridge.KernelRidge(alpha=1.0)# ON-TRADE: ,OFF-TRADE: 0.7827\n",
    "\n",
    "# #option CV\n",
    "model = linear_model.LogisticRegression(max_iter=100)\n",
    "#model = linear_model.LinearRegression()# ON-TRADE: ,OFF-TRADE: 0.7875 {'copy_X': False, 'fit_intercept': True, 'normalize': False, 'positive': False}\n",
    "#model = linear_model.Ridge(max_iter=1000)# ON-TRADE: ,OFF-TRADE: 0.7876 {'alpha': 0.005, 'copy_X': False, 'fit_intercept': True, 'normalize': True, 'solver': 'sparse_cg'}\n",
    "#model = linear_model.SGDRegressor(max_iter=1500, early_stopping=False) # ON-TRADE: ,OFF-TRADE:  0.7819 {'alpha': 0.0001, 'average': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'huber', 'penalty': 'l2', 'power_t': 0.1, 'shuffle': True, 'verbose': False, 'warm_start': True}\n",
    "\n",
    "#model = linear_model.ElasticNet(max_iter=2000)# ON-TRADE: ,OFF-TRADE: 0.7875 {'alpha': 0.001, 'copy_X': False, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': True, 'positive': False, 'precompute': False, 'selection': 'random', 'warm_start': True}\n",
    "#model = linear_model.Lars(n_nonzero_coefs=1000) # ON-TRADE: , OFF-TRADE: 0.7875 {'copy_X': True, 'fit_intercept': True, 'fit_path': True, 'jitter': False, 'normalize': False, 'precompute': False, 'verbose': True}\n",
    "#model = linear_model.LassoLars(max_iter=500) # ON-TRADE: , OFF-TRADE: 0.7875 {'alpha': 0.001, 'copy_X': True, 'fit_intercept': True, 'fit_path': True, 'jitter': False, 'normalize': True, 'positive': False, 'precompute': True, 'verbose': True}\n",
    "#model = linear_model.OrthogonalMatchingPursuit() # ON-TRADE: , OFF-TRADE: 0.7035 {'fit_intercept': True, 'normalize': True}\n",
    "#model = linear_model.ARDRegression(n_iter=500) # ON-TRADE: , OFF-TRADE: 0.7875 {'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'normalize': False, 'verbose': True}\n",
    "#model = linear_model.BayesianRidge(n_iter=500) # ON-TRADE: , OFF-TRADE: 0.7875 {'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'normalize': True, 'verbose': True}\n",
    "\n",
    "\n",
    "#NOT model = linear_model.MultiTaskElasticNet\n",
    "#NOT model = linear_model.MultiTaskLasso(max_iter=500)\n",
    "\n",
    "#model = linear_model.HuberRegressor(max_iter=500) # ON-TRADE: , OFF-TRADE: 0.7805 {'epsilon': 1.6, 'fit_intercept': True, 'warm_start': True}\n",
    "#model = linear_model.RANSACRegressor(max_trials=500) #O N-TRADE: , OFF-TRADE: 0.7225\n",
    "#model = linear_model.TheilSenRegressor(max_iter=500, n_jobs=-1) # ON-TRADE: , OFF-TRADE: 0.7582 {'copy_X': False, 'fit_intercept': True, 'verbose': True}\n",
    "\n",
    "#NOT model = linear_model.PoissonRegressor(max_iter=500)\n",
    "# model = linear_model.TweedieRegressor(max_iter=500) # ON-TRADE: , OFF-TRADE: 0.7871 {'alpha': 0.05, 'fit_intercept': False, 'link': 'auto', 'power': 0, 'warm_start': True}\n",
    "#NOT model = linear_model.GammaRegressor(max_iter=500) # ON-TRADE: ,OFF-TRADE:\n",
    "#NOT model = linear_model.PassiveAggressiveRegressor(random_state=0, fit_intercept=True) # ON-TRADE: , OFF-TRADE: 0.6938\n",
    "\n",
    "# model = neighbors.KNeighborsRegressor(n_neighbors=7, weights='uniform', leaf_size=30, n_jobs=-1) # ON-TRADE: , OFF-TRADE: 0.7941\n",
    "#NOT model = neighbors.RadiusNeighborsRegressor(radius=5.0, weights='distance')\n",
    "\n",
    "# model = neural_network.MLPRegressor(random_state=1, hidden_layer_sizes=50, max_iter=500, activation='relu', solver='adam', early_stopping=False) # ON-TRADE: , OFF-TRADE: 0.8059\n",
    "\n",
    "#NOT model = svm.LinearSVR() # ON-TRADE: , OFF-TRADE: 0.7049\n",
    "#NOT model = svm.NuSVR() # ON-TRADE: , OFF-TRADE: 0.2402\n",
    "#NOT model = svm.SVR() # ON-TRADE: , OFF-TRADE:0.2282\n",
    "\n",
    "#NOT model = tree.DecisionTreeRegressor(random_state=0, criterion='mse', splitter='best') # ON-TRADE: , OFF-TRADE: 0.6460\n",
    "#NOT model = tree.ExtraTreeRegressor(random_state=0) # ON-TRADE: , OFF-TRADE: 0.5968\n",
    "\n",
    "\n",
    "#param_grid = dict(penalty=['elasticnet'], solver=['saga'], dual=[False], fit_intercept=[True, False], warm_start=[True, False], l1_ratio=[0.5])\n",
    "#param_grid = dict(penalty=['none'], solver=['newton-cg', 'lbfgs','sag', 'saga'], dual=[True, False], fit_intercept=[True, False], warm_start=[True, False])\n",
    "param_grid = dict(penalty=['l2'], solver=['newton-cg', 'lbfgs','sag', 'saga'], dual=[True, False], fit_intercept=[True, False], warm_start=[True, False])\n",
    "param_grid = dict(penalty=['l1'], solver=['liblinear', 'saga'], dual=[True, False], fit_intercept=[True, False], warm_start=[True, False])\n",
    "\n",
    "#alpha=[1, 0.5, 0.1, 0.05, 0.001, 0.0005, 0.0001],fit_intercept=[True, False], verbose=[True, False], normalize=[True, False], precompute=[True, False], copy_X=[True, False], fit_path=[True, False], positive=[True, False], jitter=[True, False]\n",
    "clf = GridSearchCV(model, param_grid, n_jobs=3) #, random_state=0\n",
    "search = clf.fit(X_train, y_train.values.ravel())\n",
    "#print(search.cv_results_)\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "# #BEST \n",
    "# #ON-TRADE: 0.9745, 5636.8731\n",
    "# #OFF-TRADE: 0.8045, 14567.9493, without sku: (0.7934, 14149.3662)\n",
    "# #model = ensemble.HistGradientBoostingRegressor(random_state=1, loss='least_squares', learning_rate=0.05, max_iter=350, max_leaf_nodes=70, early_stopping=False)\n",
    "\n",
    "# # Train the model using the training sets\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# # Make predictions using the testing set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred[y_pred < 0] = 0\n",
    "\n",
    "# # # The mean squared error\n",
    "# # print('Mean squared error: %.4f'% mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# print(DATASET_NAME)\n",
    "# # The coefficient of determination: 1 is perfect prediction\n",
    "# print('Coefficient of determination: %.4f'% r2_score(y_test, y_pred))\n",
    "\n",
    "# # #Best possible score is 1.0, lower values are worse.\n",
    "# # print('Explained variance regression: %.4f'% explained_variance_score(y_test, y_pred))\n",
    "\n",
    "# #max_error metric calculates the maximum residual error.\n",
    "# print('Maximum residual error: %.4f'% max_error(y_test, y_pred))\n",
    "\n",
    "# # #Mean absolute percentage error regression loss.\n",
    "# # print('Mean absolute percentage error regression loss: %.4f'% mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "# print('Old Coefficient of determination: %.4f'% r2_score(y, y_oldPred))\n",
    "# print('Old Maximum residual error: %.4f'% max_error(y, y_oldPred))\n",
    "\n",
    "# # print(f'The number of iterations as selected by early stopping: {model.n_iter_}')\n",
    "# # print(f'The scores at each iteration on the training data: {model.train_score_}')\n",
    "# # print(f'The scores at each iteration on the held-out validation data: {model.validation_score_}')\n",
    "# # print(f'Boolean mask for the categorical features: {model.is_categorical_}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skater.core.explanations import Interpretation\n",
    "# from skater.model import InMemoryModel\n",
    "\n",
    "# feature_names = X_train.columns.tolist()\n",
    "# X_train_numpy = X_train[:500].to_numpy()\n",
    "\n",
    "# # wrap our base model with InMemoryModel instance\n",
    "# annotated_model = InMemoryModel(\n",
    "#     model.predict, \n",
    "#     examples = X_train_numpy, \n",
    "#     model_type = 'regressor'\n",
    "# )\n",
    "\n",
    "# interpreter = Interpretation(X_train_numpy, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.feature_importance.plot_feature_importance(annotated_model, progressbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter.partial_dependence.plot_partial_dependence(\n",
    "#     feature_names, annotated_model, grid_resolution=20, progressbar=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skater.core.local_interpretation.lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# # create an explainer\n",
    "# explainer = LimeTabularExplainer(X_train_numpy, feature_names=feature_names, mode=\"regression\")\n",
    "\n",
    "# # explain something\n",
    "# explanation = explainer.explain_instance(X_train_numpy[5], annotated_model)\n",
    "\n",
    "# # show the explanation\n",
    "# explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# #shap.initjs()\n",
    "\n",
    "# X100 = shap.utils.sample(X, 100)\n",
    "\n",
    "# explainer = shap.Explainer(model)\n",
    "# shap_values = explainer(X100)\n",
    "\n",
    "# shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.force(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.force(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.scatter(shap_values, color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = X_test.copy(deep=False)\n",
    "result[\"RealSalesHl\"] = y_test.copy(deep=False)\n",
    "result[\"PredictSalesHl\"] = y_pred\n",
    "\n",
    "dir_path = os.path.dirname(RESULT_CSV_PATH)\n",
    "if (not os.path.isdir(dir_path)):\n",
    "    os.mkdir(dir_path)\n",
    " \n",
    "result.to_csv(RESULT_CSV_PATH, index=False)\n",
    "result.to_excel(RESULT_EXCEL_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "dir_path = os.path.dirname(MODEL_PATH)\n",
    "if (not os.path.isdir(dir_path)):\n",
    "    os.mkdir(dir_path)\n",
    "\n",
    "joblib.dump(model, MODEL_PATH, compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# file = open(MODEL_PATH, 'rb')\n",
    "\n",
    "# model = joblib.load(file)\n",
    "\n",
    "# SkuShort = 2605\n",
    "# Week = 23\n",
    "# NumberWorkdays = 5\n",
    "# AvgTemp = 15.892857142857142\n",
    "# AvgRain = 3.5000000000000004\n",
    "# AvgSun = 6.735714285714286\n",
    "# IsLockdown = 0\n",
    "# PdtHl = -1.0\n",
    "# PrevWeekPdtHl1 = -1.0\n",
    "# BgtHl = 6665\n",
    "# PrevWeekBgtHl1 = 6665.949490847161\n",
    "# PrevWeekSalesHl1 = 5020\n",
    "# PrevWeekSalesHl2 = 5038\n",
    "# SalesHl = 5386.5\n",
    "\n",
    "# x = np.array([[SkuShort, Week,NumberWorkdays, AvgTemp, AvgRain, AvgSun, IsLockdown, PdtHl, PrevWeekPdtHl1, BgtHl, PrevWeekBgtHl1, PrevWeekSalesHl1, PrevWeekSalesHl2]])\n",
    "\n",
    "# y_pred = model.predict(x)\n",
    "# result = y_pred[0]\n",
    "\n",
    "# def get_percentage_diff(previous, current):\n",
    "#     return 1 - (abs(previous - current)/max(previous, current))\n",
    "\n",
    "# print('Forecast sales: %.4f hl'% result)\n",
    "# print('Coefficient of determination: %.4f'% get_percentage_diff(SalesHl, result))\n",
    "\n",
    "#full with sku = 0.7678\n",
    "#full = 0.7363"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}