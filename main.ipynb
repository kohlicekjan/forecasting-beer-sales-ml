{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting beer sales \n",
    "\n",
    "github: https://github.com/kohlicekjan/forecasting-beer-sales-ml\n",
    "\n",
    "### Source\n",
    "- https://scikit-learn.org/stable/index.html\n",
    "- https://www.mariofilho.com/how-to-predict-multiple-time-series-with-scikit-learn-with-sales-forecasting-example/\n",
    "- https://alkaline-ml.com/pmdarima/quickstart.html\n",
    "- https://facebook.github.io/prophet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'on-trade'\n",
    "\n",
    "DATA_PATH = f'./data/{DATASET_NAME}_data.csv'\n",
    "\n",
    "MODEL_PATH = f'./models/{DATASET_NAME}_model.joblib'\n",
    "\n",
    "RESULT_CSV_PATH = f'./results/{DATASET_NAME}_result.csv'\n",
    "RESULT_EXCEL_PATH = f'./results/{DATASET_NAME}_result.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  SkuShort ProductGroup PrimaryPack  Country  Year  Week  NumberWorkdays  \\\n",
       "0     1000         1000        1000        0  2016     1               5   \n",
       "1     1002         1002        1002        0  2016     1               5   \n",
       "2     1003         1003        1003        0  2016     1               5   \n",
       "3     1005         1005        1005        0  2016     1               5   \n",
       "4     1010         1010        1010        0  2016     1               5   \n",
       "\n",
       "    AvgTemp   AvgRain    AvgSun  IsLockdown  PdtHl  PrevWeekPdtHl1  \\\n",
       "0 -1.164286  0.935714  1.014286       False   -1.0            -1.0   \n",
       "1 -1.164286  0.935714  1.014286       False   -1.0            -1.0   \n",
       "2 -1.164286  0.935714  1.014286       False   -1.0            -1.0   \n",
       "3 -1.164286  0.935714  1.014286       False   -1.0            -1.0   \n",
       "4 -1.164286  0.935714  1.014286       False   -1.0            -1.0   \n",
       "\n",
       "         BgtHl  PrevWeekBgtHl1  SalesHl  PrevWeekSalesHl1  PrevWeekSalesHl2  \\\n",
       "0  1901.850666            -1.0  2057.73              -1.0              -1.0   \n",
       "1   472.938882            -1.0   394.50              -1.0              -1.0   \n",
       "2  3010.971784            -1.0  2535.60              -1.0              -1.0   \n",
       "3  4930.067934            -1.0  4515.50              -1.0              -1.0   \n",
       "4    46.150597            -1.0     7.15              -1.0              -1.0   \n",
       "\n",
       "   OldPredSalesHl  \n",
       "0       1902.0890  \n",
       "1        375.6472  \n",
       "2       2311.0085  \n",
       "3       4459.9005  \n",
       "4         40.8850  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SkuShort</th>\n      <th>ProductGroup</th>\n      <th>PrimaryPack</th>\n      <th>Country</th>\n      <th>Year</th>\n      <th>Week</th>\n      <th>NumberWorkdays</th>\n      <th>AvgTemp</th>\n      <th>AvgRain</th>\n      <th>AvgSun</th>\n      <th>IsLockdown</th>\n      <th>PdtHl</th>\n      <th>PrevWeekPdtHl1</th>\n      <th>BgtHl</th>\n      <th>PrevWeekBgtHl1</th>\n      <th>SalesHl</th>\n      <th>PrevWeekSalesHl1</th>\n      <th>PrevWeekSalesHl2</th>\n      <th>OldPredSalesHl</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>1000</td>\n      <td>1000</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-1.164286</td>\n      <td>0.935714</td>\n      <td>1.014286</td>\n      <td>False</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1901.850666</td>\n      <td>-1.0</td>\n      <td>2057.73</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1902.0890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>1002</td>\n      <td>1002</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-1.164286</td>\n      <td>0.935714</td>\n      <td>1.014286</td>\n      <td>False</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>472.938882</td>\n      <td>-1.0</td>\n      <td>394.50</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>375.6472</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>1003</td>\n      <td>1003</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-1.164286</td>\n      <td>0.935714</td>\n      <td>1.014286</td>\n      <td>False</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>3010.971784</td>\n      <td>-1.0</td>\n      <td>2535.60</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>2311.0085</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1005</td>\n      <td>1005</td>\n      <td>1005</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-1.164286</td>\n      <td>0.935714</td>\n      <td>1.014286</td>\n      <td>False</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>4930.067934</td>\n      <td>-1.0</td>\n      <td>4515.50</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>4459.9005</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1010</td>\n      <td>1010</td>\n      <td>1010</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-1.164286</td>\n      <td>0.935714</td>\n      <td>1.014286</td>\n      <td>False</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>46.150597</td>\n      <td>-1.0</td>\n      <td>7.15</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>40.8850</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 265
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_PATH, header=0, decimal=\",\")\n",
    "\n",
    "data = data.fillna(-1)\n",
    "\n",
    "#data['Date'] = data[['Year','Week']].apply(lambda x : datetime.datetime.strptime(f'{x[0]}-W{x[1]}-1', \"%Y-W%W-%w\"), axis=1)\n",
    "#data.Date = data.Date.map(datetime.datetime.toordinal)\n",
    "\n",
    "data.IsLockdown = data.IsLockdown.astype('bool')\n",
    "data.SkuShort = data.SkuShort.astype('category')\n",
    "data.ProductGroup = data.SkuShort.astype('category')\n",
    "data.PrimaryPack = data.SkuShort.astype('category')\n",
    "data.Country = data.Country.astype('category').cat.codes\n",
    "\n",
    "#data['PrevWeekSalesDiff'] = data.PrevWeekSalesHl1-data.PrevWeekSalesHl2\n",
    "\n",
    "#data = data.drop(['PrevWeekSalesHl1', 'PrevWeekSalesHl2'], axis=1)\n",
    "\n",
    "# data.at[((data.Year == 2020) & (data.Week == 50)), 'IsLockdown'] = False\n",
    "# data.at[((data.Year == 2020) & (data.Week == 51)), 'IsLockdown'] = False\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 23654 entries, 0 to 23653\nData columns (total 19 columns):\n #   Column            Non-Null Count  Dtype   \n---  ------            --------------  -----   \n 0   SkuShort          23654 non-null  category\n 1   ProductGroup      23654 non-null  category\n 2   PrimaryPack       23654 non-null  category\n 3   Country           23654 non-null  int8    \n 4   Year              23654 non-null  int64   \n 5   Week              23654 non-null  int64   \n 6   NumberWorkdays    23654 non-null  int64   \n 7   AvgTemp           23654 non-null  float64 \n 8   AvgRain           23654 non-null  float64 \n 9   AvgSun            23654 non-null  float64 \n 10  IsLockdown        23654 non-null  bool    \n 11  PdtHl             23654 non-null  float64 \n 12  PrevWeekPdtHl1    23654 non-null  float64 \n 13  BgtHl             23654 non-null  float64 \n 14  PrevWeekBgtHl1    23654 non-null  float64 \n 15  SalesHl           23654 non-null  float64 \n 16  PrevWeekSalesHl1  23654 non-null  float64 \n 17  PrevWeekSalesHl2  23654 non-null  float64 \n 18  OldPredSalesHl    23654 non-null  float64 \ndtypes: bool(1), category(3), float64(11), int64(3), int8(1)\nmemory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[(data.Year <= 2019) | ((data.Year == 2020) & (data.Week < 45))]\n",
    "test = data[(data.Year == 2020) & (data.Week >= 45)]\n",
    "\n",
    "cols_drop = ['SalesHl', 'OldPredSalesHl', 'SkuShort', 'ProductGroup', 'PrimaryPack', 'Year', 'Country', 'PdtHl', 'PrevWeekPdtHl1']\n",
    "#'SkuShort', 'ProductGroup', 'PrimaryPack', 'Country', 'Year'\n",
    "\n",
    "y_train = pd.DataFrame(train.SalesHl).round(0).astype(int)\n",
    "X_train = train.drop(cols_drop, axis=1)\n",
    "\n",
    "y_test = pd.DataFrame(test.SalesHl).round(0).astype(int)\n",
    "X_test = test.drop(cols_drop, axis=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train.head()\n",
    "\n",
    "\n",
    "y_oldPred = pd.DataFrame(test.OldPredSalesHl).fillna(0).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "on-trade\nCoefficient of determination: 0.5287\nMaximum residual error: 4197.4457\nOld Coefficient of determination: 0.4994\nOld Maximum residual error: 2890.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, max_error, mean_absolute_percentage_error\n",
    "\n",
    "from sklearn import ensemble, gaussian_process, isotonic, kernel_ridge, linear_model, neighbors, neural_network, svm, tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "# Create linear regression object\n",
    "\n",
    "#NOT model = ensemble.AdaBoostRegressor()\n",
    "#model = ensemble.BaggingRegressor() # ON-TRADE: ,OFF-TRADE: 0.79 {'base_estimator': DecisionTreeRegressor(random_state=0), 'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 200, 'oob_score': False, 'verbose': 1, 'warm_start': True}\n",
    "\n",
    "#model = ensemble.ExtraTreesRegressor(n_jobs=3) # ON-TRADE: ,OFF-TRADE: 0.7962\n",
    "\n",
    "#model = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "#model = ensemble.RandomForestRegressor(n_estimators=1000, n_jobs=6) # ON-TRADE: ,OFF-TRADE: 0.7933 {'bootstrap': True, 'criterion': 'mae', 'oob_score': True, 'warm_start': False}\n",
    "\n",
    "#NOT model = ensemble.StackingRegressor(estimators=[('lgbm', lgb.LGBMRegressor()),('hgb', ensemble.HistGradientBoostingRegressor())],final_estimator=ensemble.BaggingRegressor(), n_jobs=4, passthrough=False) \n",
    "#model = ensemble.VotingRegressor([('lgbm', lgb.LGBMRegressor(n_estimators=5000, learning_rate=0.005)), ('rf', ensemble.RandomForestRegressor(n_estimators=1000))]) # ON-TRADE: ,OFF-TRADE: 0.8143\n",
    "\n",
    "#model = ensemble.HistGradientBoostingRegressor(early_stopping=False) # ON-TRADE: ,OFF-TRADE: 0.7937 {'learning_rate': 0.01, 'loss': 'least_squares', 'max_iter': 1000, 'max_leaf_nodes': 70}\n",
    "\n",
    "#NOT model = gaussian_process.GaussianProcessRegressor()\n",
    "#NOT model = isotonic.IsotonicRegression()\n",
    "\n",
    "#NOT model = kernel_ridge.KernelRidge(alpha=1.0)# ON-TRADE: ,OFF-TRADE: 0.7827\n",
    "\n",
    "# #option CV\n",
    "#SLOW model = linear_model.LogisticRegression(max_iter=100)\n",
    "#model = linear_model.LinearRegression()# ON-TRADE: ,OFF-TRADE: 0.7875 {'copy_X': False, 'fit_intercept': True, 'normalize': False, 'positive': False}\n",
    "#model = linear_model.Ridge(max_iter=1000)# ON-TRADE: ,OFF-TRADE: 0.7876 {'alpha': 0.005, 'copy_X': False, 'fit_intercept': True, 'normalize': True, 'solver': 'sparse_cg'}\n",
    "#model = linear_model.SGDRegressor(max_iter=1500, early_stopping=False) # ON-TRADE: ,OFF-TRADE:  0.7819 {'alpha': 0.0001, 'average': True, 'epsilon': 0.1, 'eta0': 0.01, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'invscaling', 'loss': 'huber', 'penalty': 'l2', 'power_t': 0.1, 'shuffle': True, 'verbose': False, 'warm_start': True}\n",
    "\n",
    "#model = linear_model.ElasticNet(max_iter=2000)# ON-TRADE: ,OFF-TRADE: 0.7875 {'alpha': 0.001, 'copy_X': False, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': True, 'positive': False, 'precompute': False, 'selection': 'random', 'warm_start': True}\n",
    "#model = linear_model.Lars(n_nonzero_coefs=1000) # ON-TRADE: , OFF-TRADE: 0.7875 {'copy_X': True, 'fit_intercept': True, 'fit_path': True, 'jitter': False, 'normalize': False, 'precompute': False, 'verbose': True}\n",
    "#model = linear_model.LassoLars(max_iter=500) # ON-TRADE: , OFF-TRADE: 0.7875 {'alpha': 0.001, 'copy_X': True, 'fit_intercept': True, 'fit_path': True, 'jitter': False, 'normalize': True, 'positive': False, 'precompute': True, 'verbose': True}\n",
    "#model = linear_model.OrthogonalMatchingPursuit() # ON-TRADE: , OFF-TRADE: 0.7035 {'fit_intercept': True, 'normalize': True}\n",
    "#model = linear_model.ARDRegression(n_iter=500) # ON-TRADE: , OFF-TRADE: 0.7875 {'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'normalize': False, 'verbose': True}\n",
    "#model = linear_model.BayesianRidge(n_iter=500) # ON-TRADE: , OFF-TRADE: 0.7875 {'compute_score': True, 'copy_X': True, 'fit_intercept': True, 'normalize': True, 'verbose': True}\n",
    "\n",
    "\n",
    "\n",
    "#model = linear_model.HuberRegressor(max_iter=500) # ON-TRADE: , OFF-TRADE: 0.7805 {'epsilon': 1.6, 'fit_intercept': True, 'warm_start': True}\n",
    "#model = linear_model.RANSACRegressor(max_trials=500) #O N-TRADE: , OFF-TRADE: 0.7225\n",
    "#model = linear_model.TheilSenRegressor(max_iter=500, n_jobs=-1) # ON-TRADE: , OFF-TRADE: 0.7582 {'copy_X': False, 'fit_intercept': True, 'verbose': True}\n",
    "\n",
    "#NOT model = linear_model.PoissonRegressor(max_iter=500)\n",
    "# model = linear_model.TweedieRegressor(max_iter=500) # ON-TRADE: , OFF-TRADE: 0.7871 {'alpha': 0.05, 'fit_intercept': False, 'link': 'auto', 'power': 0, 'warm_start': True}\n",
    "#NOT model = linear_model.GammaRegressor(max_iter=500) # ON-TRADE: ,OFF-TRADE:\n",
    "#NOT model = linear_model.PassiveAggressiveRegressor(random_state=0, fit_intercept=True) # ON-TRADE: , OFF-TRADE: 0.6938\n",
    "\n",
    "# model = neighbors.KNeighborsRegressor(n_neighbors=7, weights='uniform', leaf_size=30, n_jobs=-1) # ON-TRADE: , OFF-TRADE: 0.7941\n",
    "#NOT model = neighbors.RadiusNeighborsRegressor(radius=5.0, weights='distance')\n",
    "\n",
    "#NOT model = svm.LinearSVR() # ON-TRADE: , OFF-TRADE: 0.7049\n",
    "\n",
    "\n",
    "\n",
    "#model = neural_network.MLPRegressor(random_state=1, hidden_layer_sizes=60, max_iter=500, early_stopping=False) # ON-TRADE: , OFF-TRADE: 0.8059\n",
    "#{'activation': 'relu', 'learning_rate': 'constant', 'nesterovs_momentum': True, 'shuffle': False, 'solver': 'adam', 'verbose': True, 'warm_start': True}\n",
    "\n",
    "model = lgb.LGBMRegressor(n_estimators=10000, learning_rate=0.001, num_leaves=300, n_jobs=6) # ON-TRADE: , OFF-TRADE: 0.8140\n",
    "\n",
    "\n",
    "#param_grid = dict(criterion=['mse','mae'])\n",
    "# #alpha=[1, 0.5, 0.1, 0.05, 0.001, 0.0005, 0.0001],fit_intercept=[True, False], verbose=[True, False], normalize=[True, False], precompute=[True, False], copy_X=[True, False], fit_path=[True, False], positive=[True, False], jitter=[True, False]\n",
    "# clf = GridSearchCV(model, param_grid, n_jobs=2) #, random_state=0\n",
    "# search = clf.fit(X_train, y_train.values.ravel())\n",
    "# #print(search.cv_results_)\n",
    "# print(search.best_score_)\n",
    "# print(search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "#BEST \n",
    "#ON-TRADE: 0.9745, 5636.8731\n",
    "#OFF-TRADE: 0.8045, 14567.9493, without sku: (0.7934, 14149.3662)\n",
    "#model = ensemble.HistGradientBoostingRegressor(random_state=1, loss='least_squares', learning_rate=0.05, max_iter=350, max_leaf_nodes=70, early_stopping=False)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "# # The mean squared error\n",
    "# print('Mean squared error: %.4f'% mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(DATASET_NAME)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.4f'% r2_score(y_test, y_pred))\n",
    "\n",
    "# #Best possible score is 1.0, lower values are worse.\n",
    "# print('Explained variance regression: %.4f'% explained_variance_score(y_test, y_pred))\n",
    "\n",
    "#max_error metric calculates the maximum residual error.\n",
    "print('Maximum residual error: %.4f'% max_error(y_test, y_pred))\n",
    "\n",
    "# #Mean absolute percentage error regression loss.\n",
    "# print('Mean absolute percentage error regression loss: %.4f'% mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "print('Old Coefficient of determination: %.4f'% r2_score(y_test, y_oldPred))\n",
    "print('Old Maximum residual error: %.4f'% max_error(y_test, y_oldPred))\n",
    "\n",
    "# print(f'The number of iterations as selected by early stopping: {model.n_iter_}')\n",
    "# print(f'The scores at each iteration on the training data: {model.train_score_}')\n",
    "# print(f'The scores at each iteration on the held-out validation data: {model.validation_score_}')\n",
    "# print(f'Boolean mask for the categorical features: {model.is_categorical_}')\n",
    "\n",
    "#0.5350 ['SalesHl', 'OldPredSalesHl', 'SkuShort', 'ProductGroup', 'PrimaryPack', 'Year', 'Country']\n",
    "#0.5404 ['SalesHl', 'OldPredSalesHl', 'SkuShort', 'ProductGroup', 'PrimaryPack', 'Year', 'Country', 'PdtHl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skater.core.explanations import Interpretation\n",
    "from skater.model import InMemoryModel\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "X_train_numpy = X_train.sample(n=500).to_numpy()\n",
    "\n",
    "# wrap our base model with InMemoryModel instance\n",
    "annotated_model = InMemoryModel(\n",
    "    model.predict, \n",
    "    examples = X_train_numpy, \n",
    "    model_type = 'regressor'\n",
    ")\n",
    "\n",
    "interpreter = Interpretation(X_train_numpy, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreter.feature_importance.plot_feature_importance(annotated_model, progressbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter.partial_dependence.plot_partial_dependence(\n",
    "#     feature_names, annotated_model, grid_resolution=20, progressbar=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skater.core.local_interpretation.lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# # create an explainer\n",
    "# explainer = LimeTabularExplainer(X_train_numpy, feature_names=feature_names, mode=\"regression\")\n",
    "\n",
    "# # explain something\n",
    "# explanation = explainer.explain_instance(X_train_numpy[5], annotated_model)\n",
    "\n",
    "# # show the explanation\n",
    "# explanation.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# #shap.initjs()\n",
    "\n",
    "# X100 = shap.utils.sample(X, 100)\n",
    "\n",
    "# explainer = shap.Explainer(model)\n",
    "# shap_values = explainer(X100)\n",
    "\n",
    "# shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.force(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.force(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.scatter(shap_values, color=shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test.copy(deep=False)\n",
    "result[\"PredictSalesHl\"] = y_pred\n",
    "\n",
    "dir_path = os.path.dirname(RESULT_CSV_PATH)\n",
    "if (not os.path.isdir(dir_path)):\n",
    "    os.mkdir(dir_path)\n",
    " \n",
    "result.to_csv(RESULT_CSV_PATH, index=False)\n",
    "result.to_excel(RESULT_EXCEL_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./models/on-trade_model.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "dir_path = os.path.dirname(MODEL_PATH)\n",
    "if (not os.path.isdir(dir_path)):\n",
    "    os.mkdir(dir_path)\n",
    "\n",
    "joblib.dump(model, MODEL_PATH, compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# file = open(MODEL_PATH, 'rb')\n",
    "\n",
    "# model = joblib.load(file)\n",
    "\n",
    "# SkuShort = 2605\n",
    "# Week = 23\n",
    "# NumberWorkdays = 5\n",
    "# AvgTemp = 15.892857142857142\n",
    "# AvgRain = 3.5000000000000004\n",
    "# AvgSun = 6.735714285714286\n",
    "# IsLockdown = 0\n",
    "# PdtHl = -1.0\n",
    "# PrevWeekPdtHl1 = -1.0\n",
    "# BgtHl = 6665\n",
    "# PrevWeekBgtHl1 = 6665.949490847161\n",
    "# PrevWeekSalesHl1 = 5020\n",
    "# PrevWeekSalesHl2 = 5038\n",
    "# SalesHl = 5386.5\n",
    "\n",
    "# x = np.array([[SkuShort, Week,NumberWorkdays, AvgTemp, AvgRain, AvgSun, IsLockdown, PdtHl, PrevWeekPdtHl1, BgtHl, PrevWeekBgtHl1, PrevWeekSalesHl1, PrevWeekSalesHl2]])\n",
    "\n",
    "# y_pred = model.predict(x)\n",
    "# result = y_pred[0]\n",
    "\n",
    "# def get_percentage_diff(previous, current):\n",
    "#     return 1 - (abs(previous - current)/max(previous, current))\n",
    "\n",
    "# print('Forecast sales: %.4f hl'% result)\n",
    "# print('Coefficient of determination: %.4f'% get_percentage_diff(SalesHl, result))\n",
    "\n",
    "#full with sku = 0.7678\n",
    "#full = 0.7363"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}